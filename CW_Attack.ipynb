{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchcodec\n",
      "  Downloading torchcodec-0.8.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Downloading torchcodec-0.8.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchcodec\n",
      "Successfully installed torchcodec-0.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchcodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453a7db74f7e40879e899d0d5e5bd4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/262 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ef87e94a6c4dc2b51e22596e0cf43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea37ccfe2fc4216b24f4bd0f2dd4979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/300 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9de866009d34c6f90aee6e00d87e677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6d9cc935124ee884a6704b7c8a8f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "# Setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"jonatasgrosman/wav2vec2-large-xlsr-53-english\"\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load Data\n",
    "speech_array, sampling_rate = torchaudio.load(\"/content/drive/MyDrive/demo.mp3\")\n",
    "resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "waveform = resampler(speech_array).squeeze()\n",
    "\n",
    "# Prepare Target\n",
    "# Because we know that uppercase and lowercase are not part of the vocabulary\n",
    "target_sentence = \"wav two vec two a s r model is under attack\"\n",
    "target_ids = processor(\n",
    "    text=target_sentence,\n",
    "    return_tensors=\"pt\"\n",
    ").input_ids.to(device)\n",
    "\n",
    "# Prepare Audio\n",
    "if waveform.ndim == 1:\n",
    "    waveform = waveform.unsqueeze(0)\n",
    "waveform = waveform.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differentiable_normalize(waveform):\n",
    "    mean = waveform.mean(dim=-1, keepdim=True)\n",
    "    var = waveform.var(dim=-1, keepdim=True, unbiased=False)\n",
    "    return (waveform - mean) / torch.sqrt(var + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_snr_db(original, perturbed):\n",
    "    noise = perturbed - original\n",
    "    signal_power = original.pow(2).mean()\n",
    "    noise_power = noise.pow(2).mean()\n",
    "    return 10 * torch.log10(signal_power / (noise_power + 1e-12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targeting: 'wav two vec two a s r model is under attack'\n",
      "Constraint: SNR must stay above 22.0 dB\n",
      "Starting Attack...\n",
      "Step 0000 | CTC Loss: 18.7194 | SNR: 32.22 dB\n",
      "Step 0100 | CTC Loss: 1.1083 | SNR: 22.00 dB\n",
      "Step 0200 | CTC Loss: 0.0081 | SNR: 22.00 dB\n",
      "Target reached with valid SNR.\n",
      "Attack Finished.\n"
     ]
    }
   ],
   "source": [
    "min_snr_db = 22.0\n",
    "signal_power = waveform.pow(2).mean()\n",
    "max_noise_power = signal_power / (10 ** (min_snr_db / 10))\n",
    "\n",
    "# Optimization Setup\n",
    "steps = 500\n",
    "learning_rate = 0.005\n",
    "\n",
    "delta = torch.zeros_like(waveform, requires_grad=True, device=device)\n",
    "optimizer = torch.optim.Adam([delta], lr=learning_rate)\n",
    "\n",
    "print(f\"Targeting: '{target_sentence}'\")\n",
    "print(f\"Constraint: SNR must stay above {min_snr_db} dB\")\n",
    "print(\"Starting Attack...\")\n",
    "\n",
    "for step in range(steps):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    adv_raw = waveform + delta\n",
    "\n",
    "    # Loss\n",
    "    adv_normalized = differentiable_normalize(adv_raw)\n",
    "    logits = model(adv_normalized).logits\n",
    "    log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "\n",
    "    input_lengths = torch.full((logits.shape[0],), logits.shape[1], dtype=torch.long, device=device)\n",
    "    target_lengths = torch.full((target_ids.shape[0],), target_ids.shape[1], dtype=torch.long, device=device)\n",
    "\n",
    "    loss = torch.nn.functional.ctc_loss(\n",
    "        log_probs.transpose(0, 1),\n",
    "        target_ids,\n",
    "        input_lengths,\n",
    "        target_lengths,\n",
    "        blank=processor.tokenizer.pad_token_id,\n",
    "        zero_infinity=True\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Check current noise power\n",
    "        current_noise_power = delta.pow(2).mean()\n",
    "\n",
    "        if current_noise_power > max_noise_power:\n",
    "            scale = torch.sqrt(max_noise_power / (current_noise_power + 1e-12))\n",
    "            delta.data *= scale\n",
    "\n",
    "        # Standard valid audio clip [-1, 1]\n",
    "        delta.data = (waveform + delta).clamp(-1.0, 1.0) - waveform\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        current_snr = compute_snr_db(waveform, waveform + delta)\n",
    "        print(f\"Step {step:04d} | CTC Loss: {loss.item():.4f} | SNR: {current_snr.item():.2f} dB\")\n",
    "\n",
    "        # Stop only if text is good\n",
    "        if loss.item() < 0.05:\n",
    "            print(\"Target reached with valid SNR.\")\n",
    "            break\n",
    "\n",
    "print(\"Attack Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verification ---\n",
      "Final SNR: 22.00 dB\n",
      "Original Target: wav two vec two a s r model is under attack\n",
      "Attack Result:   wav two vec two a s r model is under attack\n"
     ]
    }
   ],
   "source": [
    "# --- Final Verification ---\n",
    "print(\"\\n--- Verification ---\")\n",
    "adv_audio_final = (waveform + delta).detach()\n",
    "\n",
    "# Use processor normally to verify (this handles normalization internally)\n",
    "inputs = processor(\n",
    "    adv_audio_final.squeeze().cpu().numpy(),\n",
    "    sampling_rate=16000,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)[0]\n",
    "\n",
    "print(f\"Final SNR: {compute_snr_db(waveform, adv_audio_final).item():.2f} dB\")\n",
    "print(f\"Original Target: {target_sentence}\")\n",
    "print(f\"Attack Result:   {transcription}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to: /content/drive/MyDrive/adv_result_CW.wav\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/content/drive/MyDrive/adv_result_CW.wav\"\n",
    "\n",
    "torchaudio.save(save_path, adv_audio_final.cpu(), 16000)\n",
    "print(f\"Audio saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
